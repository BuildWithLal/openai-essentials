{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07acc2df-ddd4-454b-9948-a64daae25235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d348afd7-7ad2-4826-b223-d4ad41d72fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "270e9202-1a37-4c02-9322-03cb87b4e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ddba9af-a9e7-4284-a3b8-20e106588884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e924d03-c05b-415b-9d58-d6e6f2185cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31856b99-33a0-4988-9db9-2f03cb5248fe",
   "metadata": {},
   "source": [
    "## Function Calling\n",
    "connect large language models to external tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3061a39-fe9a-403f-9643-9521db8834bf",
   "metadata": {},
   "source": [
    "### Trying to get real-time data using Chat API Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5714424-d40c-4bf1-ad74-20bd618f9ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I am unable to provide real-time weather updates. I recommend checking a reliable weather website or app for the most current information on the weather in London.', role='assistant', function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the weather like today in London?\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e0f69-cecb-4ec3-976e-0847e168f535",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc38ec2a-1623-49ba-a103-982a748dc9f2",
   "metadata": {},
   "source": [
    "### Get real-time data using function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19bdac51-6010-4c4c-9a81-deb6c939d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather for a specific location\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"location\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The city, e.g., San Francisco, London\"\n",
    "            },\n",
    "            \"unit\": {\n",
    "              \"type\": \"string\",\n",
    "              \"enum\": [\"Celsius\", \"Fahrenheit\"],\n",
    "              \"description\": \"The temperature unit to use. use the correct unit here based on the user's location.\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\"location\", \"unit\"]\n",
    "        }\n",
    "      }\n",
    "    }]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b9e7e-20c3-4776-8859-085203537690",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f608dcc-c261-471e-980c-5a8e58a65998",
   "metadata": {},
   "source": [
    "### Chat model auto decides whether to use a function call or get and return output response text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "702a758e-d191-4a9d-9273-8e10a3ec64ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The Euro Cup 2024 has not yet occurred. The tournament is scheduled for June and July of 2024 in Germany. As of now, the winner has not been determined.', role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    tools=functions,\n",
    "    tool_choice=\"auto\",  # auto is default\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who won the Euro Cup 2024?\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7f708-2788-454f-8d64-b1c0a7734081",
   "metadata": {},
   "source": [
    "##### No text response from chat model but intead returning to call a function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccab23b-6619-4121-864b-3c5212bfb892",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92a1699b-4f4a-4be5-af2e-44438de6d3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_clSbR9HXQi3b3H8gGdELHyrQ', function=Function(arguments='{\"location\":\"Paris\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=functions,\n",
    "    tool_choice=\"required\",  # auto is default\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who won the last FIFA football?\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6fe99-54a4-4062-accf-b708c5e0919e",
   "metadata": {},
   "source": [
    "#### ^ Based on function, model auto detects the correct unit to be used.\n",
    "London: Celsius, New York: Fahrenheit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084c0e1-8c84-46d4-9954-8e4bfde67591",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fe12edf4-2f12-494c-84ac-82ebd379ce7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='The team with the most FIFA World Cup wins is Brazil, with a total of 5 titles.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",  # auto is default\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Which team the most FIFA World Cup wins\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88260346-c7e4-418d-b61e-8d8fb86d2fd7",
   "metadata": {},
   "source": [
    "##### Model auto decided to not suggest a function call as it has the answer for query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28233fbf-55d3-4e4c-a3e7-48638f771ec6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb71b6a2-97fd-42e6-a6c6-950fb3a08298",
   "metadata": {},
   "source": [
    "### Force model to use function call instead of output response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a2b02457-5ac9-4fbc-8b5e-9d530fde4721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UQomCCM2FoQnImM0qgJ5iQ9x', function=Function(arguments='{\"location\":\"Moscow\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=tools,\n",
    "    tool_choice=\"required\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Which team the most FIFA World Cup wins\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019dbc44-c8ad-46e4-963f-2d6d14d37bde",
   "metadata": {},
   "source": [
    "##### Even the model had a response for the query, but still suggested to call function as it was forced by the chat arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d3755-1356-466e-bec6-dfa2f37941c6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21647c68-d60c-42e4-b287-e09d02446493",
   "metadata": {},
   "source": [
    "##### Example dummy function to return the weather. This could be your backend API or an external API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e0f724c-4cdc-42c7-93be-639de99f6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"new york\" in location.lower():\n",
    "        return json.dumps({\"location\": \"New York\", \"temperature\": \"72\", \"unit\": unit})\n",
    "    elif \"london\" in location.lower():\n",
    "        return json.dumps({\"location\": \"London\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bd19ff-d38f-4a71-a3b9-d0dcdd24b6d3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c626e-3ab7-4a89-9e3c-ea0002f9a83b",
   "metadata": {},
   "source": [
    "### All in a single place to test function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c33debd1-f7a7-4fbc-aaa3-6ea36181386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_poWae8jbqMg0kXeGO7HFgMD7', function=Function(arguments='{\"location\":\"London\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')]) \n",
      "\n",
      "\n",
      "[{'role': 'user', 'content': 'What is the weather like today in London?'}, ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_poWae8jbqMg0kXeGO7HFgMD7', function=Function(arguments='{\"location\":\"London\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')]), {'tool_call_id': 'call_poWae8jbqMg0kXeGO7HFgMD7', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"London\", \"temperature\": \"22\", \"unit\": \"Celsius\"}'}] \n",
      "\n",
      "\n",
      "The weather in London today is 22 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the weather like today in London?\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=functions,\n",
    "    tool_choice=\"auto\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message, '\\n\\n')\n",
    "\n",
    "tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "# check if the model wanted to call a function\n",
    "\n",
    "if tool_calls:\n",
    "    # the JSON response may not always be valid; be sure to handle errors\n",
    "    \n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "    }\n",
    "    \n",
    "    # only one function in this example, but you can have multiple\n",
    "    \n",
    "    messages.append(response.choices[0].message)  # extend conversation with assistant's reply\n",
    "    \n",
    "    # send the info for each function call and function response to the model\n",
    "    tool_call = tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    function_response = function_to_call(\n",
    "        location=function_args.get(\"location\"),\n",
    "        unit=function_args.get(\"unit\"),\n",
    "    )\n",
    "    messages.append(\n",
    "        {\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        }\n",
    "    )\n",
    "    # extend conversation with function response\n",
    "\n",
    "    print(messages, '\\n\\n')\n",
    "    \n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    # get a new response from the model where it can see the function response\n",
    "    \n",
    "    print(second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a296a6-6543-47a0-90bf-debf2d0aaa32",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22b775f-e98c-4014-8ba6-94c763290675",
   "metadata": {},
   "source": [
    "### Make function calling re-usable by moving to a generic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "96c38cdb-9444-4625-93ce-adbb2fbd0401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_live_weather_update(messages, response, function):\n",
    "    print(\"Initial Response: \", '\\n\\n')\n",
    "    pprint.pp(response.choices[0].message, indent=4)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "    if not tool_calls:\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    available_functions = {\n",
    "        function.__name__: function,\n",
    "    }\n",
    "\n",
    "    # extend conversation with assistant's reply\n",
    "    messages.append(response.choices[0].message)\n",
    "    \n",
    "    # send the info for each function call and function response to the model\n",
    "    tool_call = tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    function_response = function_to_call(\n",
    "        location=function_args.get(\"location\"),\n",
    "        unit=function_args.get(\"unit\"),\n",
    "    )\n",
    "\n",
    "    print(\"Response from our weather API: \", '\\n\\n')\n",
    "    pprint.pp(function_response, indent=4)\n",
    "    print('\\n\\n')\n",
    "\n",
    "    # appending new message to existing messages for sending back to chat model\n",
    "    messages.append(\n",
    "        {\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"Messages going to model: \", '\\n\\n')\n",
    "    pprint.pp(messages, indent=4, depth=2)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    print(\"Final response from model: \", '\\n\\n')\n",
    "    pprint.pp(response.choices[0].message, indent=4, depth=2)\n",
    "\n",
    "    # re-send messages to chat model to generate output based on actual function call\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "60bac6dd-4a4d-48f5-bdc5-dddf52364008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Response:  \n",
      "\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_eQWT1va21pGjP8d2BkVgQd0C', function=Function(arguments='{\"location\":\"London\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')])\n",
      "\n",
      "\n",
      "\n",
      "Response from our weather API:  \n",
      "\n",
      "\n",
      "'{\"location\": \"London\", \"temperature\": \"22\", \"unit\": \"Celsius\"}'\n",
      "\n",
      "\n",
      "\n",
      "Messages going to model:  \n",
      "\n",
      "\n",
      "[   {'role': 'user', 'content': 'What was the weather like today in London?'},\n",
      "    ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_eQWT1va21pGjP8d2BkVgQd0C', function=Function(arguments='{\"location\":\"London\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')]),\n",
      "    {   'tool_call_id': 'call_eQWT1va21pGjP8d2BkVgQd0C',\n",
      "        'role': 'tool',\n",
      "        'name': 'get_current_weather',\n",
      "        'content': '{\"location\": \"London\", \"temperature\": \"22\", \"unit\": '\n",
      "                   '\"Celsius\"}'}]\n",
      "\n",
      "\n",
      "\n",
      "Final response from model:  \n",
      "\n",
      "\n",
      "ChatCompletionMessage(content='The weather in London today is 22 degrees Celsius.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The weather in London today is 22 degrees Celsius.'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What was the weather like today in London?\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "get_live_weather_update(messages, response, get_current_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9f54f6d9-4fd4-462c-9741-92156673e6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Response:  \n",
      "\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_jfa55xHeoirpLVOYJKS0qkxI', function=Function(arguments='{\"location\":\"New York\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')])\n",
      "\n",
      "\n",
      "\n",
      "Response from our weather API:  \n",
      "\n",
      "\n",
      "'{\"location\": \"New York\", \"temperature\": \"72\", \"unit\": \"Celsius\"}'\n",
      "\n",
      "\n",
      "\n",
      "Messages going to model:  \n",
      "\n",
      "\n",
      "[   {'role': 'user', 'content': 'What was the weather like today in New York?'},\n",
      "    ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_jfa55xHeoirpLVOYJKS0qkxI', function=Function(arguments='{\"location\":\"New York\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')]),\n",
      "    {   'tool_call_id': 'call_jfa55xHeoirpLVOYJKS0qkxI',\n",
      "        'role': 'tool',\n",
      "        'name': 'get_current_weather',\n",
      "        'content': '{\"location\": \"New York\", \"temperature\": \"72\", \"unit\": '\n",
      "                   '\"Celsius\"}'}]\n",
      "\n",
      "\n",
      "\n",
      "Final response from model:  \n",
      "\n",
      "\n",
      "ChatCompletionMessage(content='The weather in New York today was 72 degrees Celsius.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The weather in New York today was 72 degrees Celsius.'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What was the weather like today in New York?\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "get_live_weather_update(messages, response, get_current_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "20b9f8f6-0813-4e50-89e2-177196905b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Response:  \n",
      "\n",
      "\n",
      "ChatCompletionMessage(content='The first president of the United States was George Washington.', role='assistant', function_call=None, tool_calls=None)\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The first president of the United States was George Washington.'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who was the first president of US?\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "get_live_weather_update(messages, response, get_current_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a5f97a-b9c8-491d-8381-819733612526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
